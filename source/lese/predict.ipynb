{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ce324ade-624b-4f5c-8446-658bbc6ac614",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "# 定义深度可分离卷积层\n",
    "class DepthwiseSeparableConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=3, padding=1):\n",
    "        super(DepthwiseSeparableConv, self).__init__()\n",
    "        self.depthwise = nn.Conv2d(in_channels, in_channels, kernel_size=kernel_size, padding=padding, groups=in_channels)\n",
    "        self.pointwise = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.depthwise(x)\n",
    "        x = self.pointwise(x)\n",
    "        return x\n",
    "\n",
    "# 定义Fire模块\n",
    "class FireModule(nn.Module):\n",
    "    def __init__(self, in_channels, squeeze_channels, expand_channels):\n",
    "        super(FireModule, self).__init__()\n",
    "        self.squeeze = nn.Conv2d(in_channels, squeeze_channels, kernel_size=1)\n",
    "        self.expand1x1 = nn.Conv2d(squeeze_channels, expand_channels, kernel_size=1)\n",
    "        self.expand3x3 = nn.Conv2d(squeeze_channels, expand_channels, kernel_size=3, padding=1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.squeeze(x)\n",
    "        x = torch.relu(x)\n",
    "        return torch.cat([\n",
    "            torch.relu(self.expand1x1(x)),\n",
    "            torch.relu(self.expand3x3(x))\n",
    "        ], 1)\n",
    "\n",
    "# 定义卷积神经网络\n",
    "class DSC_CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DSC_CNN, self).__init__()\n",
    "        self.layer1 = DepthwiseSeparableConv(1, 32)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.fire = FireModule(32, 16, 32)\n",
    "        self.concat_conv = DepthwiseSeparableConv(64, 64) # 64 because FireModule output is concatenated\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.dropout = nn.Dropout(p=0.5) # 推理时默认不会调用\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(64, 4)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.pool1(x)\n",
    "        x = self.fire(x)\n",
    "        x = self.concat_conv(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.pool2(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        # 改动1：避免softmax重复计算\n",
    "        x = self.softmax(x) \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "25ba3166-4697-4f35-89b5-ed1581e6c6e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported graph: graph(%input : Float(1, 1, 32, 32, strides=[1024, 1024, 32, 1], requires_grad=0, device=cpu),\n",
      "      %layer1.depthwise.weight : Float(1, 1, 3, 3, strides=[9, 9, 3, 1], requires_grad=1, device=cpu),\n",
      "      %layer1.depthwise.bias : Float(1, strides=[1], requires_grad=1, device=cpu),\n",
      "      %layer1.pointwise.weight : Float(32, 1, 1, 1, strides=[1, 1, 1, 1], requires_grad=1, device=cpu),\n",
      "      %layer1.pointwise.bias : Float(32, strides=[1], requires_grad=1, device=cpu),\n",
      "      %fire.squeeze.weight : Float(16, 32, 1, 1, strides=[32, 1, 1, 1], requires_grad=1, device=cpu),\n",
      "      %fire.squeeze.bias : Float(16, strides=[1], requires_grad=1, device=cpu),\n",
      "      %fire.expand1x1.weight : Float(32, 16, 1, 1, strides=[16, 1, 1, 1], requires_grad=1, device=cpu),\n",
      "      %fire.expand1x1.bias : Float(32, strides=[1], requires_grad=1, device=cpu),\n",
      "      %fire.expand3x3.weight : Float(32, 16, 3, 3, strides=[144, 9, 3, 1], requires_grad=1, device=cpu),\n",
      "      %fire.expand3x3.bias : Float(32, strides=[1], requires_grad=1, device=cpu),\n",
      "      %concat_conv.depthwise.weight : Float(64, 1, 3, 3, strides=[9, 9, 3, 1], requires_grad=1, device=cpu),\n",
      "      %concat_conv.depthwise.bias : Float(64, strides=[1], requires_grad=1, device=cpu),\n",
      "      %concat_conv.pointwise.weight : Float(64, 64, 1, 1, strides=[64, 1, 1, 1], requires_grad=1, device=cpu),\n",
      "      %concat_conv.pointwise.bias : Float(64, strides=[1], requires_grad=1, device=cpu),\n",
      "      %fc.weight : Float(4, 64, strides=[64, 1], requires_grad=1, device=cpu),\n",
      "      %fc.bias : Float(4, strides=[1], requires_grad=1, device=cpu),\n",
      "      %onnx::Reshape_45 : Long(2, strides=[1], requires_grad=0, device=cpu)):\n",
      "  %input.1 : Float(1, 1, 32, 32, strides=[1024, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"Conv_0\"](%input, %layer1.depthwise.weight, %layer1.depthwise.bias) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/conv.py:454:0\n",
      "  %onnx::Relu_18 : Float(1, 32, 32, 32, strides=[32768, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"Conv_1\"](%input.1, %layer1.pointwise.weight, %layer1.pointwise.bias) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/conv.py:454:0\n",
      "  %onnx::MaxPool_19 : Float(1, 32, 32, 32, strides=[32768, 1024, 32, 1], requires_grad=1, device=cpu) = onnx::Relu[onnx_name=\"Relu_2\"](%onnx::Relu_18) # /tmp/ipykernel_28866/584637910.py:48:0\n",
      "  %input.4 : Float(1, 32, 16, 16, strides=[8192, 256, 16, 1], requires_grad=1, device=cpu) = onnx::MaxPool[ceil_mode=0, kernel_shape=[2, 2], pads=[0, 0, 0, 0], strides=[2, 2], onnx_name=\"MaxPool_3\"](%onnx::MaxPool_19) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:782:0\n",
      "  %onnx::Relu_21 : Float(1, 16, 16, 16, strides=[4096, 256, 16, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"Conv_4\"](%input.4, %fire.squeeze.weight, %fire.squeeze.bias) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/conv.py:454:0\n",
      "  %input.8 : Float(1, 16, 16, 16, strides=[4096, 256, 16, 1], requires_grad=1, device=cpu) = onnx::Relu[onnx_name=\"Relu_5\"](%onnx::Relu_21) # /tmp/ipykernel_28866/584637910.py:26:0\n",
      "  %onnx::Relu_23 : Float(1, 32, 16, 16, strides=[8192, 256, 16, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"Conv_6\"](%input.8, %fire.expand1x1.weight, %fire.expand1x1.bias) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/conv.py:454:0\n",
      "  %onnx::Concat_24 : Float(1, 32, 16, 16, strides=[8192, 256, 16, 1], requires_grad=1, device=cpu) = onnx::Relu[onnx_name=\"Relu_7\"](%onnx::Relu_23) # /tmp/ipykernel_28866/584637910.py:28:0\n",
      "  %onnx::Relu_25 : Float(1, 32, 16, 16, strides=[8192, 256, 16, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"Conv_8\"](%input.8, %fire.expand3x3.weight, %fire.expand3x3.bias) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/conv.py:454:0\n",
      "  %onnx::Concat_26 : Float(1, 32, 16, 16, strides=[8192, 256, 16, 1], requires_grad=1, device=cpu) = onnx::Relu[onnx_name=\"Relu_9\"](%onnx::Relu_25) # /tmp/ipykernel_28866/584637910.py:29:0\n",
      "  %input.12 : Float(1, 64, 16, 16, strides=[16384, 256, 16, 1], requires_grad=1, device=cpu) = onnx::Concat[axis=1, onnx_name=\"Concat_10\"](%onnx::Concat_24, %onnx::Concat_26) # /tmp/ipykernel_28866/584637910.py:30:0\n",
      "  %input.16 : Float(1, 64, 16, 16, strides=[16384, 256, 16, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=64, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"Conv_11\"](%input.12, %concat_conv.depthwise.weight, %concat_conv.depthwise.bias) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/conv.py:454:0\n",
      "  %onnx::Relu_29 : Float(1, 64, 16, 16, strides=[16384, 256, 16, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"Conv_12\"](%input.16, %concat_conv.pointwise.weight, %concat_conv.pointwise.bias) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/conv.py:454:0\n",
      "  %onnx::MaxPool_30 : Float(1, 64, 16, 16, strides=[16384, 256, 16, 1], requires_grad=1, device=cpu) = onnx::Relu[onnx_name=\"Relu_13\"](%onnx::Relu_29) # /tmp/ipykernel_28866/584637910.py:52:0\n",
      "  %input.20 : Float(1, 64, 8, 8, strides=[4096, 64, 8, 1], requires_grad=1, device=cpu) = onnx::MaxPool[ceil_mode=0, kernel_shape=[2, 2], pads=[0, 0, 0, 0], strides=[2, 2], onnx_name=\"MaxPool_14\"](%onnx::MaxPool_30) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:782:0\n",
      "  %onnx::Reshape_32 : Float(1, 64, 1, 1, strides=[64, 1, 1, 1], requires_grad=1, device=cpu) = onnx::GlobalAveragePool[onnx_name=\"GlobalAveragePool_15\"](%input.20) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:1214:0\n",
      "  %onnx::Gemm_40 : Float(1, 64, strides=[64, 1], requires_grad=1, device=cpu) = onnx::Reshape[onnx_name=\"Reshape_16\"](%onnx::Reshape_32, %onnx::Reshape_45) # /tmp/ipykernel_28866/584637910.py:56:0\n",
      "  %input.24 : Float(1, 4, strides=[4, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1, onnx_name=\"Gemm_17\"](%onnx::Gemm_40, %fc.weight, %fc.bias) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/linear.py:114:0\n",
      "  %output : Float(1, 4, strides=[4, 1], requires_grad=1, device=cpu) = onnx::Softmax[axis=1, onnx_name=\"Softmax_18\"](%input.24) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:1834:0\n",
      "  return (%output)\n",
      "\n",
      "Exporting .pth model to onnx model has been successful!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.onnx\n",
    "#from tinynet import tinynet\n",
    "import os\n",
    "\n",
    "def pth_to_onnx(input, checkpoint, onnx_path, input_names=['input'], output_names=['output'], device='cpu'):\n",
    "    if not onnx_path.endswith('.onnx'):\n",
    "        print('Warning! The onnx model name is not correct,\\\n",
    "              please give a name that ends with \\'.onnx\\'!')\n",
    "        return 0\n",
    "\n",
    "    #model = tinynet() #导入模型\n",
    "    model = DSC_CNN()\n",
    "    model.load_state_dict(torch.load(checkpoint, map_location=torch.device(device))) #初始化权重\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    input = input.to(device)\n",
    "    \n",
    "    torch.onnx.export(model, input, onnx_path, verbose=True, input_names=input_names, output_names=output_names) #指定模型的输入，以及onnx的输出路径\n",
    "    print(\"Exporting .pth model to onnx model has been successful!\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    model_name = 'model01'\n",
    "    os.environ['CUDA_VISIBLE_DEVICES']='2'\n",
    "    device = torch.device(\"cuda:2\" if torch.cuda.is_available() else 'cpu')\n",
    "    checkpoint = '../save/' + model_name + \".pth\"\n",
    "    checkpoint = '../save/' + model_name + \".pth\"\n",
    "    onnx_path = '../save/' + model_name +\".onnx\" \n",
    "    input = torch.randn(1, 1, 32, 32)\n",
    "    pth_to_onnx(input, checkpoint, onnx_path, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f4aa8dbc-1a56-409d-8778-3b9209cb9f64",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] Unable to open file (unable to open file: name = '../data/try/data_test_small.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_28866/4271945957.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'../data/try/data_test_small.h5'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_hdf5\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_28866/4271945957.py\u001b[0m in \u001b[0;36mread_hdf5\u001b[0;34m(filename, dataset_name)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mread_hdf5\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'dataset'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdataset_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdataset_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, fs_page_size, page_buf_size, min_meta_keep, min_raw_keep, locking, alignment_threshold, alignment_interval, meta_block_size, **kwds)\u001b[0m\n\u001b[1;32m    565\u001b[0m                                  \u001b[0mfs_persist\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfs_persist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfs_threshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfs_threshold\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    566\u001b[0m                                  fs_page_size=fs_page_size)\n\u001b[0;32m--> 567\u001b[0;31m                 \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_fid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muserblock_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mswmr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mswmr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    568\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlibver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m    229\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mswmr\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m             \u001b[0mflags\u001b[0m \u001b[0;34m|=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_SWMR_READ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 231\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    232\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'r+'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_RDWR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.open\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] Unable to open file (unable to open file: name = '../data/try/data_test_small.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "def read_hdf5(filename, dataset_name='dataset'):\n",
    "    with h5py.File(filename, 'r') as f:\n",
    "        if dataset_name in f:\n",
    "            data = f[dataset_name][:]\n",
    "        else:\n",
    "            raise KeyError(f\"数据集 '{dataset_name}' 不存在\")\n",
    "    return torch.tensor(data)\n",
    "\n",
    "filename = '../data/try/data_test_small.h5'\n",
    "\n",
    "data = read_hdf5(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43858f5c-8903-4742-a488-0865b83f028c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install onnxruntime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2cc4990b-eaa8-41c4-9393-624b8fac07a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Name: input\n",
      "Input Shape: [1, 1, 32, 32]\n",
      "Input Type: tensor(float)\n",
      "Output: [array([[3.7362389e-07, 1.0970704e-02, 1.1392456e-06, 9.8902774e-01]],\n",
      "      dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "import onnxruntime as ort\n",
    "import numpy as np\n",
    "\n",
    "# 加载 ONNX 模型\n",
    "onnx_path = '../save/' + model_name +\".onnx\"\n",
    "session = ort.InferenceSession(onnx_path)\n",
    "\n",
    "# 获取模型的输入名称和输入形状\n",
    "input_name = session.get_inputs()[0].name\n",
    "input_shape = session.get_inputs()[0].shape\n",
    "input_type = session.get_inputs()[0].type\n",
    "\n",
    "# 打印输入信息\n",
    "print(f\"Input Name: {input_name}\")\n",
    "print(f\"Input Shape: {input_shape}\")\n",
    "print(f\"Input Type: {input_type}\")\n",
    "\n",
    "# 创建一个模拟输入数据\n",
    "# 注意：这里需要根据模型的实际输入形状和数据类型进行调整\n",
    "input_data = np.random.rand(*input_shape).astype(np.float32)\n",
    "\n",
    "# 运行推理\n",
    "output = session.run(None, {input_name: input_data})\n",
    "\n",
    "# 获取输出\n",
    "# 如果模型有多个输出，可以通过 session.get_outputs() 获取所有输出名称\n",
    "print(\"Output:\", output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d2l",
   "language": "python",
   "name": "d2l"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
